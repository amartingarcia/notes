{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to My Notes \u00b6 In this repository I write my notes about different technologies.","title":"Home"},{"location":"#welcome-to-my-notes","text":"In this repository I write my notes about different technologies.","title":"Welcome to My Notes"},{"location":"cicd/jenkins/jenkins/","text":"Jenkins \u00b6 Jenkins","title":"Jenkins"},{"location":"cicd/jenkins/jenkins/#jenkins","text":"Jenkins","title":"Jenkins"},{"location":"cicd/jenkins/jenkinsfile/","text":"Jenkinsfiles \u00b6 On this section declare some Jenkinsfile documentated. Example 1 Example 2 Example 3 Example 4 Example 5 Example 6","title":"Jenkinsfiles"},{"location":"cicd/jenkins/jenkinsfile/#jenkinsfiles","text":"On this section declare some Jenkinsfile documentated. Example 1 Example 2 Example 3 Example 4 Example 5 Example 6","title":"Jenkinsfiles"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_1/","text":"Example 1 \u00b6 // Available environments in which it can be deployed ENVIRONMENTS = [ \"DEV\": [ \"KUBERNETES\": \"<kubernetes-agent>\", \"POD\": \"pod.yaml\", \"LABEL\": \"label\" ], \"PRO\": [ \"KUBERNETES\": \"<kubernetes-agent>\", \"POD\": \"pod.yaml\", \"LABEL\": \"label\" ], ] pipeline { ///////////////////////////////////////////////////////////////////////////////////// // - Start pipeline // ///////////////////////////////////////////////////////////////////////////////////// options { // It allows to keep the pipeline, for 8 hours. timeout(time: 8, unit: 'HOURS') disableConcurrentBuilds() } parameters { // Gets a list of available environments to deploy, and offers them as input parameters choice(name: 'environment', choices: ENVIRONMENTS.keySet() as List, description: 'Environment where deploy' ) } triggers { // UTC - will take place between 23:01 and 23:09 UTC+2 (\"H\" allows you to choose from a range of time) cron( env.BRANCH_NAME.equals('main') ? 'H(1-29) 21 * * *' : '') } // By default everything runs in the cluster. Except the execution of the scripts. agent { kubernetes { cloud \"<kubernetes-agent>\" label \"label-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"alpine\" } } stages { ///////////////////////////////////////////////////////////////////////////////////// // - Start stages // ///////////////////////////////////////////////////////////////////////////////////// // Stage that allows the creation of tags through semantic-release stage('Semantic Release') { when { // It will only be executed when it is built in any of the defined branches anyOf{ branch \"main\" branch \"dev\" } beforeAgent true } steps { container('node'){ withCredentials([ sshUserPrivateKey(credentialsId: 'credential-id', keyFileVariable: 'credential-key-file')]) { sh \"\"\" export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${credential-key-file}' apk add nodejs npm git openssh bash coreutils npm install -g semantic-release semantic-release/git -D semantic-release --debug --plugins \"@semantic-release/git\" \"\"\" } } } // `step` closing } // `stage` closing // Stage that allows to obtain the last tag created in the repository, and to build it stage('Calling tag job: PRO') { when { allOf{ branch \"main\" triggeredBy 'TimerTrigger' } beforeAgent true } steps { container('alpine'){ // Get the last tag created for main branch. Example, main: v1.1.1. script{ sh 'apk add coreutils git' MAIN_GIT_LATEST_TAG = sh ( script: \"git tag | sort --version-sort | grep -vi 'dev' | tail -1\", returnStdout: true ).trim() print(\"debug(MAIN_GIT_LATEST_TAG): \" + MAIN_GIT_LATEST_TAG) } // It will run the job, with the last tag created for the main branch. build job: \"devops/job/${MAIN_GIT_LATEST_TAG}\", wait: false, parameters: [ string(name: 'environment', value: 'PRO' ) ] } } // `step` closing } // `stage` closing // Stage that allows to install all the necessary packages to execute the script stage('Preparing workspace') { when { allOf{ tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" } } steps { container('python'){ // Prepare apk cache sh ''' mkdir $WORKSPACE/apt-cache ln -sf /var/cache/apt $WORKSPACE/apt-cache apt update ''' // Download Python dependencies while builinding virtualenv sh ''' apt install -y virtualenv ''' // Prepare virtualenv sh ''' mkdir $WORKSPACE/virtualenv virtualenv -p python3 virtualenv/.venv $WORKSPACE/virtualenv/.venv/bin/pip3 install wheel $WORKSPACE/virtualenv/.venv/bin/pip3 install -r $WORKSPACE/requirements.txt ''' // Stash created environment stash includes: 'apt-cache/**', name: 'apt-cache' stash includes: 'virtualenv/**', name: 'virtualenv' } } // `step` closing } // `stage` closing // Stage that allows to execute the script stage('Deploy environment') { agent { // Will obtain the data of the selected environment during the construction of the tag in Jenkins kubernetes { cloud ENVIRONMENTS[params.environment][\"KUBERNETES\"] label ENVIRONMENTS[params.environment][\"LABEL\"] yamlFile ENVIRONMENTS[params.environment][\"POD\"] } } when { allOf{ // will only run if the regex matches tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" } beforeAgent true } steps { container('python'){ // Unstash files from cluster unstash 'apt-cache' unstash 'virtualenv' retry(3){ sh 'ln -sf $WORKSPACE/apt-cache/apt /var/cache/apt' sh 'apt update && apt install -y virtualenv' // Data source with the variables necessary for the execution of the script sh '''#!/bin/bash echo \"Exec script\" ''' } } } // `step` closing } // `stage` closing } // `all stages` closing post { // If the execution of the pipeline failed or aborted, an email will be sent to the recipients. failure { mail body: \"<b>Jenkins</b><br>Project: ${env.JOB_NAME} <br>Build Number: ${env.BUILD_NUMBER} <br> URL build: ${env.BUILD_URL}\", subject: \"Jenkins Build Failed: Project name -> ${env.JOB_NAME}\", mimeType: 'text/html', to: \"\" } aborted { mail body: \"<b>Jenkins</b><br>Project: ${env.JOB_NAME} <br>Build Number: ${env.BUILD_NUMBER} <br> URL build: ${env.BUILD_URL}\", subject: \"Jenkins Build Aborted: Project name -> ${env.JOB_NAME}\", mimeType: 'text/html', to: \"\" } } // `post actions` closing } // `pipeline` closing","title":"Example 1"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_1/#example-1","text":"// Available environments in which it can be deployed ENVIRONMENTS = [ \"DEV\": [ \"KUBERNETES\": \"<kubernetes-agent>\", \"POD\": \"pod.yaml\", \"LABEL\": \"label\" ], \"PRO\": [ \"KUBERNETES\": \"<kubernetes-agent>\", \"POD\": \"pod.yaml\", \"LABEL\": \"label\" ], ] pipeline { ///////////////////////////////////////////////////////////////////////////////////// // - Start pipeline // ///////////////////////////////////////////////////////////////////////////////////// options { // It allows to keep the pipeline, for 8 hours. timeout(time: 8, unit: 'HOURS') disableConcurrentBuilds() } parameters { // Gets a list of available environments to deploy, and offers them as input parameters choice(name: 'environment', choices: ENVIRONMENTS.keySet() as List, description: 'Environment where deploy' ) } triggers { // UTC - will take place between 23:01 and 23:09 UTC+2 (\"H\" allows you to choose from a range of time) cron( env.BRANCH_NAME.equals('main') ? 'H(1-29) 21 * * *' : '') } // By default everything runs in the cluster. Except the execution of the scripts. agent { kubernetes { cloud \"<kubernetes-agent>\" label \"label-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"alpine\" } } stages { ///////////////////////////////////////////////////////////////////////////////////// // - Start stages // ///////////////////////////////////////////////////////////////////////////////////// // Stage that allows the creation of tags through semantic-release stage('Semantic Release') { when { // It will only be executed when it is built in any of the defined branches anyOf{ branch \"main\" branch \"dev\" } beforeAgent true } steps { container('node'){ withCredentials([ sshUserPrivateKey(credentialsId: 'credential-id', keyFileVariable: 'credential-key-file')]) { sh \"\"\" export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${credential-key-file}' apk add nodejs npm git openssh bash coreutils npm install -g semantic-release semantic-release/git -D semantic-release --debug --plugins \"@semantic-release/git\" \"\"\" } } } // `step` closing } // `stage` closing // Stage that allows to obtain the last tag created in the repository, and to build it stage('Calling tag job: PRO') { when { allOf{ branch \"main\" triggeredBy 'TimerTrigger' } beforeAgent true } steps { container('alpine'){ // Get the last tag created for main branch. Example, main: v1.1.1. script{ sh 'apk add coreutils git' MAIN_GIT_LATEST_TAG = sh ( script: \"git tag | sort --version-sort | grep -vi 'dev' | tail -1\", returnStdout: true ).trim() print(\"debug(MAIN_GIT_LATEST_TAG): \" + MAIN_GIT_LATEST_TAG) } // It will run the job, with the last tag created for the main branch. build job: \"devops/job/${MAIN_GIT_LATEST_TAG}\", wait: false, parameters: [ string(name: 'environment', value: 'PRO' ) ] } } // `step` closing } // `stage` closing // Stage that allows to install all the necessary packages to execute the script stage('Preparing workspace') { when { allOf{ tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" } } steps { container('python'){ // Prepare apk cache sh ''' mkdir $WORKSPACE/apt-cache ln -sf /var/cache/apt $WORKSPACE/apt-cache apt update ''' // Download Python dependencies while builinding virtualenv sh ''' apt install -y virtualenv ''' // Prepare virtualenv sh ''' mkdir $WORKSPACE/virtualenv virtualenv -p python3 virtualenv/.venv $WORKSPACE/virtualenv/.venv/bin/pip3 install wheel $WORKSPACE/virtualenv/.venv/bin/pip3 install -r $WORKSPACE/requirements.txt ''' // Stash created environment stash includes: 'apt-cache/**', name: 'apt-cache' stash includes: 'virtualenv/**', name: 'virtualenv' } } // `step` closing } // `stage` closing // Stage that allows to execute the script stage('Deploy environment') { agent { // Will obtain the data of the selected environment during the construction of the tag in Jenkins kubernetes { cloud ENVIRONMENTS[params.environment][\"KUBERNETES\"] label ENVIRONMENTS[params.environment][\"LABEL\"] yamlFile ENVIRONMENTS[params.environment][\"POD\"] } } when { allOf{ // will only run if the regex matches tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" } beforeAgent true } steps { container('python'){ // Unstash files from cluster unstash 'apt-cache' unstash 'virtualenv' retry(3){ sh 'ln -sf $WORKSPACE/apt-cache/apt /var/cache/apt' sh 'apt update && apt install -y virtualenv' // Data source with the variables necessary for the execution of the script sh '''#!/bin/bash echo \"Exec script\" ''' } } } // `step` closing } // `stage` closing } // `all stages` closing post { // If the execution of the pipeline failed or aborted, an email will be sent to the recipients. failure { mail body: \"<b>Jenkins</b><br>Project: ${env.JOB_NAME} <br>Build Number: ${env.BUILD_NUMBER} <br> URL build: ${env.BUILD_URL}\", subject: \"Jenkins Build Failed: Project name -> ${env.JOB_NAME}\", mimeType: 'text/html', to: \"\" } aborted { mail body: \"<b>Jenkins</b><br>Project: ${env.JOB_NAME} <br>Build Number: ${env.BUILD_NUMBER} <br> URL build: ${env.BUILD_URL}\", subject: \"Jenkins Build Aborted: Project name -> ${env.JOB_NAME}\", mimeType: 'text/html', to: \"\" } } // `post actions` closing } // `pipeline` closing","title":"Example 1"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_2/","text":"Example 2 \u00b6 // Name of the repository and its download link def map1 = [ \"repo1_map1\" : \"<git-url>\", \"repo2_map1\" : \"<git-url>\" ] def map2 = [ \"repo1_map2\" : \"<git-url>\", \"repo2_map2\" : \"<git-url>\", \"repo3_map2\" : \"<git-url>\" ] def map3 = [ \"repo1_map3\" : \"<git-url>\", \"repo2_map3\" : \"<git-url>\", \"repo3_map3\" : \"<git-url>\" ] // Environment where we want to deploy ENVIRONMENTS = [ \"DEV\": [ \"KUBERNETES\": \"kubernetes-agent-dev\", ], \"PRE\": [ \"KUBERNETES\": \"kubernetes-agent-pre\", ], \"PRO\": [ \"KUBERNETES\": \"kubernetes-agent-pro\", ] ] pipeline { parameters { choice(name: 'environment', choices: ENVIRONMENTS.keySet() as List, description: 'List of all available environments') } agent { kubernetes { cloud \"kubernetes\" label \"app-all-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"alpine\" } } stages { stage('Preparing workspace') { steps { sh ''' apk update apk add coreutils git openssh-client bash ''' } // `step` closing } // `stage` closing stage (' Deploy phase 1') { steps { script { // Dynamic Stages are generated, as many compo repositories have been declared map1.each { entry -> stage (entry.key) { withCredentials([ sshUserPrivateKey( credentialsId: 'credential-id', keyFileVariable: 'key') ]) { sh \"\"\" mkdir -p $WORKSPACE/$entry.key export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${key}' git clone $entry.value $WORKSPACE/$entry.key \"\"\" } // The last tag of each repository is obtained to launch its construction script{ GIT_LATEST_TAG = sh ( script: \"cd $WORKSPACE/$entry.key && git tag | sort --version-sort | grep -i v | tail -1\", returnStdout: true ).trim() print(\"debug(GIT_LATEST_TAG): \" + GIT_LATEST_TAG) } // The job is built with the last tag found and the one with the indicated input parameter. build job: \"Devops/job/$entry.key/${GIT_LATEST_TAG}\", parameters: [ string(name: 'environment', value: params.environment ) ] } } } } // `step` closing } // `stage` closing stage (' Deploy phase 2') { steps { script { // Dynamic Stages are generated, as many compo repositories have been declared map2.each { entry -> stage (entry.key) { withCredentials([ sshUserPrivateKey( credentialsId: 'credential-id', keyFileVariable: 'key') ]) { sh \"\"\" mkdir -p $WORKSPACE/$entry.key export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${key}' git clone $entry.value $WORKSPACE/$entry.key \"\"\" } // The last tag of each repository is obtained to launch its construction script{ GIT_LATEST_TAG = sh ( script: \"cd $WORKSPACE/$entry.key && git tag | sort --version-sort | grep -i v | tail -1\", returnStdout: true ).trim() print(\"debug(GIT_LATEST_TAG): \" + GIT_LATEST_TAG) } // The job is built with the last tag found and the one with the indicated input parameter. build job: \"Devops/job/$entry.key/${GIT_LATEST_TAG}\", parameters: [ string(name: 'environment', value: params.environment ) ] } } } } // `step` closing } // `stage` closing stage (' Deploy phase 3') { steps { script { // Dynamic Stages are generated, as many compo repositories have been declared map3.each { entry -> stage (entry.key) { withCredentials([ sshUserPrivateKey( credentialsId: 'credential-id', keyFileVariable: 'key') ]) { sh \"\"\" mkdir -p $WORKSPACE/$entry.key export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${key}' git clone $entry.value $WORKSPACE/$entry.key \"\"\" } // The last tag of each repository is obtained to launch its construction script{ GIT_LATEST_TAG = sh ( script: \"cd $WORKSPACE/$entry.key && git tag | sort --version-sort | grep -i v | tail -1\", returnStdout: true ).trim() print(\"debug(GIT_LATEST_TAG): \" + GIT_LATEST_TAG) } // The job is built with the last tag found and the one with the indicated input parameter. build job: \"Devops/job/$entry.key/${GIT_LATEST_TAG}\", parameters: [ string(name: 'environment', value: params.environment ) ] } } } } // `step` closing } // `stage` closing } // all stages } // pipeline","title":"Example 2"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_2/#example-2","text":"// Name of the repository and its download link def map1 = [ \"repo1_map1\" : \"<git-url>\", \"repo2_map1\" : \"<git-url>\" ] def map2 = [ \"repo1_map2\" : \"<git-url>\", \"repo2_map2\" : \"<git-url>\", \"repo3_map2\" : \"<git-url>\" ] def map3 = [ \"repo1_map3\" : \"<git-url>\", \"repo2_map3\" : \"<git-url>\", \"repo3_map3\" : \"<git-url>\" ] // Environment where we want to deploy ENVIRONMENTS = [ \"DEV\": [ \"KUBERNETES\": \"kubernetes-agent-dev\", ], \"PRE\": [ \"KUBERNETES\": \"kubernetes-agent-pre\", ], \"PRO\": [ \"KUBERNETES\": \"kubernetes-agent-pro\", ] ] pipeline { parameters { choice(name: 'environment', choices: ENVIRONMENTS.keySet() as List, description: 'List of all available environments') } agent { kubernetes { cloud \"kubernetes\" label \"app-all-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"alpine\" } } stages { stage('Preparing workspace') { steps { sh ''' apk update apk add coreutils git openssh-client bash ''' } // `step` closing } // `stage` closing stage (' Deploy phase 1') { steps { script { // Dynamic Stages are generated, as many compo repositories have been declared map1.each { entry -> stage (entry.key) { withCredentials([ sshUserPrivateKey( credentialsId: 'credential-id', keyFileVariable: 'key') ]) { sh \"\"\" mkdir -p $WORKSPACE/$entry.key export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${key}' git clone $entry.value $WORKSPACE/$entry.key \"\"\" } // The last tag of each repository is obtained to launch its construction script{ GIT_LATEST_TAG = sh ( script: \"cd $WORKSPACE/$entry.key && git tag | sort --version-sort | grep -i v | tail -1\", returnStdout: true ).trim() print(\"debug(GIT_LATEST_TAG): \" + GIT_LATEST_TAG) } // The job is built with the last tag found and the one with the indicated input parameter. build job: \"Devops/job/$entry.key/${GIT_LATEST_TAG}\", parameters: [ string(name: 'environment', value: params.environment ) ] } } } } // `step` closing } // `stage` closing stage (' Deploy phase 2') { steps { script { // Dynamic Stages are generated, as many compo repositories have been declared map2.each { entry -> stage (entry.key) { withCredentials([ sshUserPrivateKey( credentialsId: 'credential-id', keyFileVariable: 'key') ]) { sh \"\"\" mkdir -p $WORKSPACE/$entry.key export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${key}' git clone $entry.value $WORKSPACE/$entry.key \"\"\" } // The last tag of each repository is obtained to launch its construction script{ GIT_LATEST_TAG = sh ( script: \"cd $WORKSPACE/$entry.key && git tag | sort --version-sort | grep -i v | tail -1\", returnStdout: true ).trim() print(\"debug(GIT_LATEST_TAG): \" + GIT_LATEST_TAG) } // The job is built with the last tag found and the one with the indicated input parameter. build job: \"Devops/job/$entry.key/${GIT_LATEST_TAG}\", parameters: [ string(name: 'environment', value: params.environment ) ] } } } } // `step` closing } // `stage` closing stage (' Deploy phase 3') { steps { script { // Dynamic Stages are generated, as many compo repositories have been declared map3.each { entry -> stage (entry.key) { withCredentials([ sshUserPrivateKey( credentialsId: 'credential-id', keyFileVariable: 'key') ]) { sh \"\"\" mkdir -p $WORKSPACE/$entry.key export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${key}' git clone $entry.value $WORKSPACE/$entry.key \"\"\" } // The last tag of each repository is obtained to launch its construction script{ GIT_LATEST_TAG = sh ( script: \"cd $WORKSPACE/$entry.key && git tag | sort --version-sort | grep -i v | tail -1\", returnStdout: true ).trim() print(\"debug(GIT_LATEST_TAG): \" + GIT_LATEST_TAG) } // The job is built with the last tag found and the one with the indicated input parameter. build job: \"Devops/job/$entry.key/${GIT_LATEST_TAG}\", parameters: [ string(name: 'environment', value: params.environment ) ] } } } } // `step` closing } // `stage` closing } // all stages } // pipeline","title":"Example 2"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_3/","text":"Example 3 \u00b6 PROJECTS = [ \"\": [], \"project1\": [\"ENV_ZONE\": \"us-central1-b\"], \"project2\": [\"ENV_ZONE\": \"us-central1-b\"] ] // ALL ACTIONS ACTIONS = ['', 'APPLY', 'DIFF', 'TEMPLATE'] // ALL RELEASES RELEASES = [ '', 'APP1', 'APP2', ] pipeline { parameters { choice(name: 'ACTION', choices: ACTIONS, description: 'Action over tenant') choice(name: 'RELEASE', choices: RELEASES, description: 'Release to deploy') choice(name: 'PROJECT', choices: PROJECTS.keySet() as List, description: 'Deploy resource on account') } options { buildDiscarder(logRotator(numToKeepStr: '20')) ansiColor('xterm') } environment { env_CREDENTIALS_ID = \"env-${params.PROJECT.toLowerCase()}\" env_PROJECT = \"${params.PROJECT.toLowerCase()}\" env_ZONE = \"${PROJECTS[params.PROJECT][\"env_ZONE\"].toLowerCase()}\" } agent { kubernetes { cloud \"kubernetes\" label \"provider-env-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"provider-env\" } } stages { stage('(env) Prepare config') { when { allOf { expression { ACTION != '' } branch 'main' } beforeAgent true } steps { withCredentials([file(credentialsId: env.env_CREDENTIALS_ID, variable: 'env_RESOURCE_PROJECT_FILE')]) { sh \"\"\"#!/bin/bash # CONFIGURE RESOURCE PROJECT gcloud auth activate-service-account --key-file=${env_RESOURCE_PROJECT_FILE} # CONFIGURE KUBERNETES CREDENTIALS gcloud container clusters get-credentials ${env.env_PROJECT} --zone ${env.env_ZONE} --project ${env.env_PROJECT} \"\"\" } } // `steps` closing } // `stage (env) Prepare config` closing stage('(Helmfile) Action') { when { allOf { expression { ACTION != '' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa'), file(credentialsId: env.env_CREDENTIALS_ID, variable: 'env_RESOURCE_PROJECT_FILE') ]) { sh(\"\"\" export GOOGLE_APPLICATION_CREDENTIALS=${env_RESOURCE_PROJECT_FILE} cd charts/ helmfile deps helmfile -e ${env.env_PROJECT} -l name=${params.RELEASE.toLowerCase()} ${params.ACTION.toLowerCase()} \"\"\") } } } // `steps` closing } // `stage (Helmfile) Action` closing } // `all stages` closing } // `pipeline` closing","title":"Example 3"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_3/#example-3","text":"PROJECTS = [ \"\": [], \"project1\": [\"ENV_ZONE\": \"us-central1-b\"], \"project2\": [\"ENV_ZONE\": \"us-central1-b\"] ] // ALL ACTIONS ACTIONS = ['', 'APPLY', 'DIFF', 'TEMPLATE'] // ALL RELEASES RELEASES = [ '', 'APP1', 'APP2', ] pipeline { parameters { choice(name: 'ACTION', choices: ACTIONS, description: 'Action over tenant') choice(name: 'RELEASE', choices: RELEASES, description: 'Release to deploy') choice(name: 'PROJECT', choices: PROJECTS.keySet() as List, description: 'Deploy resource on account') } options { buildDiscarder(logRotator(numToKeepStr: '20')) ansiColor('xterm') } environment { env_CREDENTIALS_ID = \"env-${params.PROJECT.toLowerCase()}\" env_PROJECT = \"${params.PROJECT.toLowerCase()}\" env_ZONE = \"${PROJECTS[params.PROJECT][\"env_ZONE\"].toLowerCase()}\" } agent { kubernetes { cloud \"kubernetes\" label \"provider-env-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"provider-env\" } } stages { stage('(env) Prepare config') { when { allOf { expression { ACTION != '' } branch 'main' } beforeAgent true } steps { withCredentials([file(credentialsId: env.env_CREDENTIALS_ID, variable: 'env_RESOURCE_PROJECT_FILE')]) { sh \"\"\"#!/bin/bash # CONFIGURE RESOURCE PROJECT gcloud auth activate-service-account --key-file=${env_RESOURCE_PROJECT_FILE} # CONFIGURE KUBERNETES CREDENTIALS gcloud container clusters get-credentials ${env.env_PROJECT} --zone ${env.env_ZONE} --project ${env.env_PROJECT} \"\"\" } } // `steps` closing } // `stage (env) Prepare config` closing stage('(Helmfile) Action') { when { allOf { expression { ACTION != '' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa'), file(credentialsId: env.env_CREDENTIALS_ID, variable: 'env_RESOURCE_PROJECT_FILE') ]) { sh(\"\"\" export GOOGLE_APPLICATION_CREDENTIALS=${env_RESOURCE_PROJECT_FILE} cd charts/ helmfile deps helmfile -e ${env.env_PROJECT} -l name=${params.RELEASE.toLowerCase()} ${params.ACTION.toLowerCase()} \"\"\") } } } // `steps` closing } // `stage (Helmfile) Action` closing } // `all stages` closing } // `pipeline` closing","title":"Example 3"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_4/","text":"Example 4 \u00b6 pipeline { ///////////////////////////////////////////////////////////////////////////////////// // - Start pipeline // ///////////////////////////////////////////////////////////////////////////////////// agent { kubernetes { label \"image-updater\" yamlFile \"pod.yaml\" defaultContainer \"kaniko\" } } options { disableConcurrentBuilds() buildDiscarder(logRotator(numToKeepStr: '10')) } triggers { // Every monday between 9:00 and 11:59 cron('H(0-59) H(9-11) * * 1') } stages { ///////////////////////////////////////////////////////////////////////////////////// // - Start stages // ///////////////////////////////////////////////////////////////////////////////////// stage('Preparing workspace') { environment { version = VersionNumber(versionNumberString: '${BUILD_YEAR}.${BUILD_MONTH}.${BUILDS_THIS_MONTH}') } steps { withCredentials([ file(credentialsId: 'cred', variable: 'DOCKER_CONFIG'), ]) { sh 'cp \"${DOCKER_CONFIG}\" /kaniko/.docker/config.json' } } } // If you run a pull request for testing purposes will not create lastest tag stage('Creating testing images') { when { branch \"PR-*\" } environment { version = VersionNumber(versionNumberString: '${BUILD_YEAR}.${BUILD_MONTH}.${BUILDS_THIS_MONTH}') } steps { sh '''#!/busybox/sh for IMAGE in $WORKSPACE/images/*; do IMAGE=$(basename $IMAGE) /kaniko/executor \\ --reproducible \\ --context=\"${WORKSPACE}/images/${IMAGE}\" \\ --destination=\"artifact.com/devops//${IMAGE}:${version}\" done ''' } } stage('Creating new images') { when { branch \"main\" } environment { version = VersionNumber(versionNumberString: '${BUILD_YEAR}.${BUILD_MONTH}.${BUILDS_THIS_MONTH}') } steps { sh '''#!/busybox/sh for IMAGE in $WORKSPACE/images/*; do IMAGE=$(basename $IMAGE) /kaniko/executor \\ --reproducible \\ --context=\"${WORKSPACE}/images/${IMAGE}\" \\ --destination=\"artifact.com/devops/${IMAGE}:${version}\" \\ --destination=\"artifact.com//devops/${IMAGE}:latest\" done ''' } } } } // `steps` and `pipeline` closing","title":"Example 4"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_4/#example-4","text":"pipeline { ///////////////////////////////////////////////////////////////////////////////////// // - Start pipeline // ///////////////////////////////////////////////////////////////////////////////////// agent { kubernetes { label \"image-updater\" yamlFile \"pod.yaml\" defaultContainer \"kaniko\" } } options { disableConcurrentBuilds() buildDiscarder(logRotator(numToKeepStr: '10')) } triggers { // Every monday between 9:00 and 11:59 cron('H(0-59) H(9-11) * * 1') } stages { ///////////////////////////////////////////////////////////////////////////////////// // - Start stages // ///////////////////////////////////////////////////////////////////////////////////// stage('Preparing workspace') { environment { version = VersionNumber(versionNumberString: '${BUILD_YEAR}.${BUILD_MONTH}.${BUILDS_THIS_MONTH}') } steps { withCredentials([ file(credentialsId: 'cred', variable: 'DOCKER_CONFIG'), ]) { sh 'cp \"${DOCKER_CONFIG}\" /kaniko/.docker/config.json' } } } // If you run a pull request for testing purposes will not create lastest tag stage('Creating testing images') { when { branch \"PR-*\" } environment { version = VersionNumber(versionNumberString: '${BUILD_YEAR}.${BUILD_MONTH}.${BUILDS_THIS_MONTH}') } steps { sh '''#!/busybox/sh for IMAGE in $WORKSPACE/images/*; do IMAGE=$(basename $IMAGE) /kaniko/executor \\ --reproducible \\ --context=\"${WORKSPACE}/images/${IMAGE}\" \\ --destination=\"artifact.com/devops//${IMAGE}:${version}\" done ''' } } stage('Creating new images') { when { branch \"main\" } environment { version = VersionNumber(versionNumberString: '${BUILD_YEAR}.${BUILD_MONTH}.${BUILDS_THIS_MONTH}') } steps { sh '''#!/busybox/sh for IMAGE in $WORKSPACE/images/*; do IMAGE=$(basename $IMAGE) /kaniko/executor \\ --reproducible \\ --context=\"${WORKSPACE}/images/${IMAGE}\" \\ --destination=\"artifact.com/devops/${IMAGE}:${version}\" \\ --destination=\"artifact.com//devops/${IMAGE}:latest\" done ''' } } } } // `steps` and `pipeline` closing","title":"Example 4"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_5/","text":"Example 5 \u00b6 // @Library(\"sonar@lts\") _ // Available Environments ENVIRONMENTS = [ \"dev\": [ \"KUBERNETES\": \"agent-dev\", \"POD\": \"pod.yaml\", ], \"pro\": [ \"KUBERNETES\": \"agent-pro\", \"POD\": \"pod.yaml\", ] ] // Available Microservices MICROSERVICES = [ \"ALL\", \"MICRO1\", \"MICRO2\" ] pipeline { ///////////////////////////////////////////////////////////////////////////////////// // - Start pipeline // ///////////////////////////////////////////////////////////////////////////////////// agent { kubernetes { cloud \"kubernetes\" label \"builder\" yamlFile \"pod.yaml\" defaultContainer \"node\" } } options { disableConcurrentBuilds() } parameters { choice(name: 'ENVIRONMENT', choices: ENVIRONMENTS.keySet() as List, description: 'Environment where deploy' ) choice(name: 'MICROSERVICE', choices: MICROSERVICES, description: 'Microservice deploy' ) } environment { DOCKER_REGISTRY = \"registry.com\" REPOSITORY_NAME = \"repo\" HELM_RELEASE = \"release\" TAG = \"${env.GIT_BRANCH.toLowerCase()}\" // This will have main, tag or pr-id TENANT = \"${params.ENVIRONMENT.toLowerCase()}\" MICROSERVICE = \"${params.MICROSERVICE.toLowerCase()}\" DOCKER_URL = \"${DOCKER_REGISTRY}/${REPOSITORY_NAME}\" NAMESPACE = \"default\" } stages { ///////////////////////////////////////////////////////////////////////////////////// // - Start stages // ///////////////////////////////////////////////////////////////////////////////////// stage(\"Prepare python environment\") { when { branch 'PR-*' } steps { container(\"python\") { sh ''' apt-get update apt-get install --no-install-recommends --yes git openssh-client curl make postgresql-client pip install --upgrade pip pip install -r requirements-tests.txt ''' // Restore dumps for unit tests sh 'psql -h localhost -p 5432 -U postgres < $WORKSPACE/tools/database/postgres/security_assets.sql' // Ingest data in Elastic ephemeral for unit tests sh 'python3 $WORKSPACE/tools/database/elastic/elastic.py' } } // `step` closing } // `stage` closing stage('Tag release') { when { branch \"main\" } steps { container(\"semantic-release\") { script { withCredentials([ sshUserPrivateKey(credentialsId: 'cred', keyFileVariable: 'id_rsa') ]) { sh ''' export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' apk add curl sed git openssh semantic-release --plugins \"@semantic-release/git\" ''' } } } } // `step` closing } // `stage` closing stage('Tests') { when { branch 'PR-*' } environment { LC_ALL = 'en_US.UTF-8' LANG = 'en_US.UTF-8' } failFast false parallel { stage('Checkstyle test') { steps { container(\"python\") { sh 'make lint' } } // `step` closing } // `stage` closing } // `pararell` closing } // `main stage` closing stage('Update Catalogue') { when { branch \"main\" } steps { container(\"python\") { script { withCredentials([ sshUserPrivateKey(credentialsId: 'cred', keyFileVariable: 'id_rsa') ]) { sh ''' apt-get update apt-get install --no-install-recommends --yes git openssh-client export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' git checkout $GIT_BRANCH git remote add versioner $GIT_URL git fetch versioner ''' // Execute catalogue script sh 'python3 $WORKSPACE/tools/catalogue/example.py' // Push changes to bitbucket sh ''' export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' AUTHOR=\\$(git show --format=\"%ae\" $GIT_COMMIT | head -1 | awk -F'@' '{ print $1 }') EMAIL=\\$(git show --format=\"%ae\" $GIT_COMMIT | head -1) git config user.name \\\\\"$AUTHOR\\\\\" && git config user.email \\\\\"$EMAIL\\\\\" git add . git diff-index --quiet HEAD || git commit -m \"docs(catalogue): Update catalogue\" git push origin $GIT_BRANCH ''' } } } } } stage('Build image') { when { beforeAgent true anyOf{ tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" branch 'PR-*' } } steps { sh 'echo \"${TAG}\" > $WORKSPACE/VERSION' container(\"kaniko\") { withCredentials([ file(credentialsId: 'cred', variable: 'DOCKER_CONFIG'),]) { sh 'cp \"${DOCKER_CONFIG}\" /kaniko/.docker/config.json' } sh '''#!/busybox/sh /kaniko/executor \\ --reproducible \\ --context=\"${WORKSPACE}\" \\ --destination=\"${DOCKER_URL}:${TAG}\" ''' } } // `step` closing } // `stage` closing stage('Deploy preview environment') { when { beforeAgent true branch 'PR-*' } agent { kubernetes { cloud ENVIRONMENTS[\"DEV\"][\"KUBERNETES\"] label \"preview\" yamlFile ENVIRONMENTS[\"DEV\"][\"POD\"] } } environment { ingress = \"app-${TAG}.${NAMESPACE}-dns.internal\" preview_values = \"ephemeral.yaml\" } steps { container(\"helmfile\") { dir(\"charts\") { sh ''' echo \"appVersion: ${TAG}\" >> releases/base/${HELM_RELEASE}/Chart.yaml sed -i \"s/- host: TO_BE_FILLED_BY_CI/- host: ${ingress}/\" bases/${preview_values} ''' sh ''' helmfile -l name=${HELM_RELEASE}-secrets -e DEV-ephemeral apply ''' sh ''' helmfile -e DEV-ephemeral apply ''' } } } // `step` closing } // `stage` closing stage('Deploy environment: All microservices') { when { beforeAgent true tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" allOf{ expression { params.MICROSERVICE == 'ALL'} expression { params.ENVIRONMENT == 'DEV' || params.ENVIRONMENT == 'PRO' } } } agent { kubernetes { cloud ENVIRONMENTS[params.ENVIRONMENT][\"KUBERNETES\"] label \"deployer-${params.ENVIRONMENT.toLowerCase()}\" yamlFile ENVIRONMENTS[params.ENVIRONMENT][\"POD\"] } } steps { container(\"helmfile\") { dir(\"charts\") { sh ''' echo \"appVersion: ${TAG}\" >> releases/base/${HELM_RELEASE}/Chart.yaml ''' sh ''' helmfile -l name=${HELM_RELEASE}-secrets -e ${TENANT} apply ''' sh ''' helmfile -e ${TENANT} apply ''' } } } // `step` closing } // `stage` closing stage('Deploy to environment: Single microservices') { when { beforeAgent true tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" anyOf{ expression { params.MICROSERVICE != 'ALL'} } } agent { kubernetes { cloud ENVIRONMENTS[params.ENVIRONMENT][\"KUBERNETES\"] label \"PRO-deployer-${params.ENVIRONMENT.toLowerCase()}\" yamlFile ENVIRONMENTS[params.ENVIRONMENT][\"POD\"] } } steps { container(\"helmfile\") { dir(\"charts\") { sh ''' echo \"appVersion: ${TAG}\" >> releases/base/${HELM_RELEASE}/Chart.yaml ''' sh ''' helmfile -l name=${HELM_RELEASE}-secrets -e ${TENANT} apply ''' sh ''' helmfile -l name=${HELM_RELEASE}-${MICROSERVICE} -e ${TENANT} apply ''' } } } // `step` closing } // `stage` closing } // `all stages` closing } // `pipeline` closing","title":"Example 5"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_5/#example-5","text":"// @Library(\"sonar@lts\") _ // Available Environments ENVIRONMENTS = [ \"dev\": [ \"KUBERNETES\": \"agent-dev\", \"POD\": \"pod.yaml\", ], \"pro\": [ \"KUBERNETES\": \"agent-pro\", \"POD\": \"pod.yaml\", ] ] // Available Microservices MICROSERVICES = [ \"ALL\", \"MICRO1\", \"MICRO2\" ] pipeline { ///////////////////////////////////////////////////////////////////////////////////// // - Start pipeline // ///////////////////////////////////////////////////////////////////////////////////// agent { kubernetes { cloud \"kubernetes\" label \"builder\" yamlFile \"pod.yaml\" defaultContainer \"node\" } } options { disableConcurrentBuilds() } parameters { choice(name: 'ENVIRONMENT', choices: ENVIRONMENTS.keySet() as List, description: 'Environment where deploy' ) choice(name: 'MICROSERVICE', choices: MICROSERVICES, description: 'Microservice deploy' ) } environment { DOCKER_REGISTRY = \"registry.com\" REPOSITORY_NAME = \"repo\" HELM_RELEASE = \"release\" TAG = \"${env.GIT_BRANCH.toLowerCase()}\" // This will have main, tag or pr-id TENANT = \"${params.ENVIRONMENT.toLowerCase()}\" MICROSERVICE = \"${params.MICROSERVICE.toLowerCase()}\" DOCKER_URL = \"${DOCKER_REGISTRY}/${REPOSITORY_NAME}\" NAMESPACE = \"default\" } stages { ///////////////////////////////////////////////////////////////////////////////////// // - Start stages // ///////////////////////////////////////////////////////////////////////////////////// stage(\"Prepare python environment\") { when { branch 'PR-*' } steps { container(\"python\") { sh ''' apt-get update apt-get install --no-install-recommends --yes git openssh-client curl make postgresql-client pip install --upgrade pip pip install -r requirements-tests.txt ''' // Restore dumps for unit tests sh 'psql -h localhost -p 5432 -U postgres < $WORKSPACE/tools/database/postgres/security_assets.sql' // Ingest data in Elastic ephemeral for unit tests sh 'python3 $WORKSPACE/tools/database/elastic/elastic.py' } } // `step` closing } // `stage` closing stage('Tag release') { when { branch \"main\" } steps { container(\"semantic-release\") { script { withCredentials([ sshUserPrivateKey(credentialsId: 'cred', keyFileVariable: 'id_rsa') ]) { sh ''' export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' apk add curl sed git openssh semantic-release --plugins \"@semantic-release/git\" ''' } } } } // `step` closing } // `stage` closing stage('Tests') { when { branch 'PR-*' } environment { LC_ALL = 'en_US.UTF-8' LANG = 'en_US.UTF-8' } failFast false parallel { stage('Checkstyle test') { steps { container(\"python\") { sh 'make lint' } } // `step` closing } // `stage` closing } // `pararell` closing } // `main stage` closing stage('Update Catalogue') { when { branch \"main\" } steps { container(\"python\") { script { withCredentials([ sshUserPrivateKey(credentialsId: 'cred', keyFileVariable: 'id_rsa') ]) { sh ''' apt-get update apt-get install --no-install-recommends --yes git openssh-client export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' git checkout $GIT_BRANCH git remote add versioner $GIT_URL git fetch versioner ''' // Execute catalogue script sh 'python3 $WORKSPACE/tools/catalogue/example.py' // Push changes to bitbucket sh ''' export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' AUTHOR=\\$(git show --format=\"%ae\" $GIT_COMMIT | head -1 | awk -F'@' '{ print $1 }') EMAIL=\\$(git show --format=\"%ae\" $GIT_COMMIT | head -1) git config user.name \\\\\"$AUTHOR\\\\\" && git config user.email \\\\\"$EMAIL\\\\\" git add . git diff-index --quiet HEAD || git commit -m \"docs(catalogue): Update catalogue\" git push origin $GIT_BRANCH ''' } } } } } stage('Build image') { when { beforeAgent true anyOf{ tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" branch 'PR-*' } } steps { sh 'echo \"${TAG}\" > $WORKSPACE/VERSION' container(\"kaniko\") { withCredentials([ file(credentialsId: 'cred', variable: 'DOCKER_CONFIG'),]) { sh 'cp \"${DOCKER_CONFIG}\" /kaniko/.docker/config.json' } sh '''#!/busybox/sh /kaniko/executor \\ --reproducible \\ --context=\"${WORKSPACE}\" \\ --destination=\"${DOCKER_URL}:${TAG}\" ''' } } // `step` closing } // `stage` closing stage('Deploy preview environment') { when { beforeAgent true branch 'PR-*' } agent { kubernetes { cloud ENVIRONMENTS[\"DEV\"][\"KUBERNETES\"] label \"preview\" yamlFile ENVIRONMENTS[\"DEV\"][\"POD\"] } } environment { ingress = \"app-${TAG}.${NAMESPACE}-dns.internal\" preview_values = \"ephemeral.yaml\" } steps { container(\"helmfile\") { dir(\"charts\") { sh ''' echo \"appVersion: ${TAG}\" >> releases/base/${HELM_RELEASE}/Chart.yaml sed -i \"s/- host: TO_BE_FILLED_BY_CI/- host: ${ingress}/\" bases/${preview_values} ''' sh ''' helmfile -l name=${HELM_RELEASE}-secrets -e DEV-ephemeral apply ''' sh ''' helmfile -e DEV-ephemeral apply ''' } } } // `step` closing } // `stage` closing stage('Deploy environment: All microservices') { when { beforeAgent true tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" allOf{ expression { params.MICROSERVICE == 'ALL'} expression { params.ENVIRONMENT == 'DEV' || params.ENVIRONMENT == 'PRO' } } } agent { kubernetes { cloud ENVIRONMENTS[params.ENVIRONMENT][\"KUBERNETES\"] label \"deployer-${params.ENVIRONMENT.toLowerCase()}\" yamlFile ENVIRONMENTS[params.ENVIRONMENT][\"POD\"] } } steps { container(\"helmfile\") { dir(\"charts\") { sh ''' echo \"appVersion: ${TAG}\" >> releases/base/${HELM_RELEASE}/Chart.yaml ''' sh ''' helmfile -l name=${HELM_RELEASE}-secrets -e ${TENANT} apply ''' sh ''' helmfile -e ${TENANT} apply ''' } } } // `step` closing } // `stage` closing stage('Deploy to environment: Single microservices') { when { beforeAgent true tag pattern: \"^v\\\\d+.\\\\d+.\\\\d+(-[0-9a-zA-Z\\\\.]+)?\\$\", comparator: \"REGEXP\" anyOf{ expression { params.MICROSERVICE != 'ALL'} } } agent { kubernetes { cloud ENVIRONMENTS[params.ENVIRONMENT][\"KUBERNETES\"] label \"PRO-deployer-${params.ENVIRONMENT.toLowerCase()}\" yamlFile ENVIRONMENTS[params.ENVIRONMENT][\"POD\"] } } steps { container(\"helmfile\") { dir(\"charts\") { sh ''' echo \"appVersion: ${TAG}\" >> releases/base/${HELM_RELEASE}/Chart.yaml ''' sh ''' helmfile -l name=${HELM_RELEASE}-secrets -e ${TENANT} apply ''' sh ''' helmfile -l name=${HELM_RELEASE}-${MICROSERVICE} -e ${TENANT} apply ''' } } } // `step` closing } // `stage` closing } // `all stages` closing } // `pipeline` closing","title":"Example 5"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_6/","text":"Example 6 \u00b6 TENANTS = [ \"\": [], \"dev\": [ \"AWS_DEFAULT_REGION\": \"us-east-1\", \"AWS_CREDENTIALS\": \"aws-dev\", \"AWS_ASSUME_ROLE_ARN\": \"arn:aws:iam::000000000000:role/dev\", \"AWS_EXTERNAL_ID\": \"000000000000\", \"SSH_KEY\": \"dev-key\", \"TENANT\": \"dev\", ], \"pro\": [ \"AWS_DEFAULT_REGION\": \"us-east-1\", \"AWS_CREDENTIALS\": \"aws-pro\", \"AWS_ASSUME_ROLE_ARN\": \"arn:aws:iam::111111111111:role/dev\", \"AWS_EXTERNAL_ID\": \"111111111111\", \"SSH_KEY\": \"pro-key\", \"TENANT\": \"pro\", ] ] // @function: terraform def terraform(status) { sh \"\"\"#!/bin/bash # VARS export AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' export TF_VAR_aws_assume_role_arn=\"${AWS_ASSUME_ROLE_ARN}\" export TF_VAR_aws_external_id=\"${AWS_EXTERNAL_ID}\" # WOKRKDIR cd ${WORKSPACE}/terraform/tenant/${TENANT}/ # Show current dir echo \"###########################################\" for i in \\$(ls -d */ | cut -d \" \" -f10); do echo \"Terraform directory: \\${i}\" done echo \"###########################################\" for i in \\$(ls -d */ | cut -d \" \" -f10); do cd ${WORKSPACE}/terraform/tenant/${TENANT}/\\${i}/ echo \"The current workdir is: \\${i}\" # EXECUTION ## get modules and instance backend terraform init \\ -backend-config=\"role_arn=\\${AWS_ASSUME_ROLE_ARN}\" \\ -backend-config=\"external_id=\\${AWS_EXTERNAL_ID}\" ## validate syntax and show changes terraform validate tflint --init ## conditional to deploy/destroy or plan if [[ \"${status}\" != \"plan\" ]]; then terraform ${status} -auto-approve else terraform ${status} fi done \"\"\" } pipeline { parameters { choice(name: 'ACTION', choices: ['', 'DEPLOY', 'PLAN', 'DESTROY'], description: 'Action over tenant') choice(name: 'TENANT', choices: TENANTS.keySet() as List, description: 'Deploy tenant') } options { buildDiscarder(logRotator(numToKeepStr: '20')) ansiColor('xterm') } environment { ANSIBLE_FORCE_COLOR = true AWS_ASSUME_ROLE_ARN = \"${TENANTS[params.TENANT][\"AWS_ASSUME_ROLE_ARN\"]}\" AWS_CREDENTIALS = \"${TENANTS[params.TENANT][\"AWS_CREDENTIALS\"]}\" AWS_DEFAULT_REGION = \"${TENANTS[params.TENANT][\"AWS_DEFAULT_REGION\"]}\" AWS_EXTERNAL_ID = \"${TENANTS[params.TENANT][\"AWS_EXTERNAL_ID\"]}\" SSH_KEY = \"${TENANTS[params.TENANT][\"SSH_KEY\"]}\" TENANT = \"${TENANTS[params.TENANT][\"TENANT\"]}\" TFLINT_LOG = \"info\" } agent { kubernetes { cloud \"kubernetes\" label \"k8s-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"alpine\" } } stages { stage('(AWS) Prepare config') { when { allOf { expression { ACTION != '' } branch 'main' } beforeAgent true } steps { withAWS(credentials: AWS_CREDENTIALS) { sh \"\"\"#!/bin/bash # HOTFIX: config permission chown root:root /root/.ssh/config chmod 644 /root/.ssh/config # AWS configs mkdir -p ~/.aws ## config echo \"[profile default]\" >> ~/.aws/config echo \"output = json\" >> ~/.aws/config echo \"region = ${env.AWS_DEFAULT_REGION}\" >> ~/.aws/config echo \"role_arn = ${env.AWS_ASSUME_ROLE_ARN}\" >> ~/.aws/config echo \"source_profile = default\" >> ~/.aws/config echo \"external_id = ${env.AWS_EXTERNAL_ID}\" >> ~/.aws/config ## credentials echo \"[default]\" >> ~/.aws/credentials echo \"aws_access_key_id = ${env.AWS_ACCESS_KEY_ID}\" >> ~/.aws/credentials echo \"aws_secret_access_key = ${env.AWS_SECRET_ACCESS_KEY}\" >> ~/.aws/credentials \"\"\" } } // `steps` closing } // `stage (AWS) Prepare config` closing stage('(Terraform) Review changes') { when { allOf { expression { ACTION == 'PLAN' || ACTION == 'DEPLOY' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withAWS(credentials: AWS_CREDENTIALS) { withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa') ]) { // execute terraform plan terraform('plan') } } } } // `steps` closing } // `stage (Terraform) Review changes` closing stage('(Terraform) Deploy infraestructure') { when { allOf { expression { ACTION == 'DEPLOY' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withAWS(credentials: AWS_CREDENTIALS) { withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa') ]) { // execute terraform apply terraform('apply') } } } } // `steps` closing } // `stage (Terraform) Deploy infraestructure` closing stage('(Terraform) Destroy infraestructure') { when { allOf { expression { ACTION == 'DESTROY' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withAWS(credentials: AWS_CREDENTIALS) { withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa') ]) { // execute terraform destroy terraform('destroy') } } } } // `steps` closing } // `stage (Terraform) Destroy infraestructure` closing } // `all stages` closing } // `pipeline` closing","title":"Example 6"},{"location":"cicd/jenkins/jenkinsfiles/jenkinsfile_6/#example-6","text":"TENANTS = [ \"\": [], \"dev\": [ \"AWS_DEFAULT_REGION\": \"us-east-1\", \"AWS_CREDENTIALS\": \"aws-dev\", \"AWS_ASSUME_ROLE_ARN\": \"arn:aws:iam::000000000000:role/dev\", \"AWS_EXTERNAL_ID\": \"000000000000\", \"SSH_KEY\": \"dev-key\", \"TENANT\": \"dev\", ], \"pro\": [ \"AWS_DEFAULT_REGION\": \"us-east-1\", \"AWS_CREDENTIALS\": \"aws-pro\", \"AWS_ASSUME_ROLE_ARN\": \"arn:aws:iam::111111111111:role/dev\", \"AWS_EXTERNAL_ID\": \"111111111111\", \"SSH_KEY\": \"pro-key\", \"TENANT\": \"pro\", ] ] // @function: terraform def terraform(status) { sh \"\"\"#!/bin/bash # VARS export AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} export GIT_SSH_COMMAND='ssh -o StrictHostKeyChecking=no -o IdentitiesOnly=yes -i ${id_rsa}' export TF_VAR_aws_assume_role_arn=\"${AWS_ASSUME_ROLE_ARN}\" export TF_VAR_aws_external_id=\"${AWS_EXTERNAL_ID}\" # WOKRKDIR cd ${WORKSPACE}/terraform/tenant/${TENANT}/ # Show current dir echo \"###########################################\" for i in \\$(ls -d */ | cut -d \" \" -f10); do echo \"Terraform directory: \\${i}\" done echo \"###########################################\" for i in \\$(ls -d */ | cut -d \" \" -f10); do cd ${WORKSPACE}/terraform/tenant/${TENANT}/\\${i}/ echo \"The current workdir is: \\${i}\" # EXECUTION ## get modules and instance backend terraform init \\ -backend-config=\"role_arn=\\${AWS_ASSUME_ROLE_ARN}\" \\ -backend-config=\"external_id=\\${AWS_EXTERNAL_ID}\" ## validate syntax and show changes terraform validate tflint --init ## conditional to deploy/destroy or plan if [[ \"${status}\" != \"plan\" ]]; then terraform ${status} -auto-approve else terraform ${status} fi done \"\"\" } pipeline { parameters { choice(name: 'ACTION', choices: ['', 'DEPLOY', 'PLAN', 'DESTROY'], description: 'Action over tenant') choice(name: 'TENANT', choices: TENANTS.keySet() as List, description: 'Deploy tenant') } options { buildDiscarder(logRotator(numToKeepStr: '20')) ansiColor('xterm') } environment { ANSIBLE_FORCE_COLOR = true AWS_ASSUME_ROLE_ARN = \"${TENANTS[params.TENANT][\"AWS_ASSUME_ROLE_ARN\"]}\" AWS_CREDENTIALS = \"${TENANTS[params.TENANT][\"AWS_CREDENTIALS\"]}\" AWS_DEFAULT_REGION = \"${TENANTS[params.TENANT][\"AWS_DEFAULT_REGION\"]}\" AWS_EXTERNAL_ID = \"${TENANTS[params.TENANT][\"AWS_EXTERNAL_ID\"]}\" SSH_KEY = \"${TENANTS[params.TENANT][\"SSH_KEY\"]}\" TENANT = \"${TENANTS[params.TENANT][\"TENANT\"]}\" TFLINT_LOG = \"info\" } agent { kubernetes { cloud \"kubernetes\" label \"k8s-${env.BRANCH_NAME}-${env.BUILD_NUMBER}\" yamlFile \"pod.yaml\" defaultContainer \"alpine\" } } stages { stage('(AWS) Prepare config') { when { allOf { expression { ACTION != '' } branch 'main' } beforeAgent true } steps { withAWS(credentials: AWS_CREDENTIALS) { sh \"\"\"#!/bin/bash # HOTFIX: config permission chown root:root /root/.ssh/config chmod 644 /root/.ssh/config # AWS configs mkdir -p ~/.aws ## config echo \"[profile default]\" >> ~/.aws/config echo \"output = json\" >> ~/.aws/config echo \"region = ${env.AWS_DEFAULT_REGION}\" >> ~/.aws/config echo \"role_arn = ${env.AWS_ASSUME_ROLE_ARN}\" >> ~/.aws/config echo \"source_profile = default\" >> ~/.aws/config echo \"external_id = ${env.AWS_EXTERNAL_ID}\" >> ~/.aws/config ## credentials echo \"[default]\" >> ~/.aws/credentials echo \"aws_access_key_id = ${env.AWS_ACCESS_KEY_ID}\" >> ~/.aws/credentials echo \"aws_secret_access_key = ${env.AWS_SECRET_ACCESS_KEY}\" >> ~/.aws/credentials \"\"\" } } // `steps` closing } // `stage (AWS) Prepare config` closing stage('(Terraform) Review changes') { when { allOf { expression { ACTION == 'PLAN' || ACTION == 'DEPLOY' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withAWS(credentials: AWS_CREDENTIALS) { withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa') ]) { // execute terraform plan terraform('plan') } } } } // `steps` closing } // `stage (Terraform) Review changes` closing stage('(Terraform) Deploy infraestructure') { when { allOf { expression { ACTION == 'DEPLOY' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withAWS(credentials: AWS_CREDENTIALS) { withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa') ]) { // execute terraform apply terraform('apply') } } } } // `steps` closing } // `stage (Terraform) Deploy infraestructure` closing stage('(Terraform) Destroy infraestructure') { when { allOf { expression { ACTION == 'DESTROY' } branch 'main' } beforeAgent true } steps { script { // LOAD CREDENTIALS withAWS(credentials: AWS_CREDENTIALS) { withCredentials([ sshUserPrivateKey(credentialsId: \"cred\", keyFileVariable: 'id_rsa') ]) { // execute terraform destroy terraform('destroy') } } } } // `steps` closing } // `stage (Terraform) Destroy infraestructure` closing } // `all stages` closing } // `pipeline` closing","title":"Example 6"},{"location":"git/multi_accounts/","text":"Multi-Accounts \u00b6 Sometimes it may be necessary to set up different git accounts for different directories. In my computer I use the following configuration: ~/.ssh/config.d/git Host github.com HostName github.com User git IdentityFile ~/.ssh/keys/github Host ssh.dev.azure.com HostName ssh.dev.azure.com User git IdentityFile ~/.ssh/keys/azdevops ~/.gitconfig [user] name = fullname-fake email = username-fake@company-fake.com [includeIf \"gitdir:~/repos/personal/\"] path = ~/repos/personal/.gitconfig ~/repo/personal/.gitconfig [user] name = personal-username-fake email = personal-email-fake","title":"Multi-accounts"},{"location":"git/multi_accounts/#multi-accounts","text":"Sometimes it may be necessary to set up different git accounts for different directories. In my computer I use the following configuration: ~/.ssh/config.d/git Host github.com HostName github.com User git IdentityFile ~/.ssh/keys/github Host ssh.dev.azure.com HostName ssh.dev.azure.com User git IdentityFile ~/.ssh/keys/azdevops ~/.gitconfig [user] name = fullname-fake email = username-fake@company-fake.com [includeIf \"gitdir:~/repos/personal/\"] path = ~/repos/personal/.gitconfig ~/repo/personal/.gitconfig [user] name = personal-username-fake email = personal-email-fake","title":"Multi-Accounts"},{"location":"kubernetes/kops/","text":"kOps \u00b6 Example file \u00b6 # kOps Cluster definition apiVersion: kops.k8s.io/v1alpha2 kind: Cluster metadata: ## Cluster name name: cluster.example spec: api: loadBalancer: class: Network type: Public assets: containerProxy: registry.com:9090 authorization: rbac: {} channel: stable cloudProvider: aws ## Bucket name and state file configBase: s3://bucket-name/cluster.example dnsZone: zone.example etcdClusters: - name: main cpuRequest: 200m etcdMembers: - instanceGroup: master-1 name: etcd-1 - instanceGroup: master-2 name: etcd-2 - instanceGroup: master-3 name: etcd-3 memoryRequest: 100Mi - name: events cpuRequest: 100m etcdMembers: - instanceGroup: master-1 name: etcd-1 - instanceGroup: master-2 name: etcd-2 - instanceGroup: master-3 name: etcd-3 memoryRequest: 100Mi iam: legacy: false ## Kubelet config kubelet: ### Enable to use metrics-server anonymousAuth: false ### Allow serviceaccount tokens to communicate with kubelet authorizationMode: Webhook authenticationTokenWebhook: true ## VPC CIDR access to Kubernetes API Server kubernetesApiAccess: [] kubernetesVersion: 1.22.6 masterPublicName: api.cluster.example ## VPC CIDR networkCIDR: 10.3.0.0/16 ## VPC ID networkID: vpc-00000000000 networking: ## CNI calico: majorVersion: v3 ### maximum transmission unit mtu: 1500 ## Internal kubernetes CIDR nonMasqueradeCIDR: 110.64.0.0/10 sshAccess: null subnets: - cidr: 12.0.0.0/24 id: subnet-00000000000 name: utility-eu-west-1c type: Utility zone: eu-west-1c - cidr: 10.3.2.0/23 id: subnet-1111111111 name: eu-west-1c type: Private zone: eu-west-1c topology: dns: type: Private masters: private nodes: private ## Addons awsLoadBalancerController: enabled: false clusterAutoscaler: enabled: true awsUseStaticInstanceList: false balanceSimilarNodeGroups: false expander: random image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.22.3 maxNodeProvisionTime: 15m0s newPodScaleUpDelay: 0s scaleDownDelayAfterAdd: 10m0s scaleDownUtilizationThreshold: \"0.5\" skipNodesWithLocalStorage: true skipNodesWithSystemPods: true cloudConfig: awsEBSCSIDriver: enabled: false managed: false nodeProblemDetector: enabled: true memoryRequest: 32Mi cpuRequest: 10m --- # IG master-1 apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: master-1 spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 autoscale: false iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 ## master set max = 1 min = 1 minSize: 1 maxSize: 1 machineType: c5a.large ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: master-1 project: master ## Labels for AWS cloudLabels: environment: Dev role: Master subnets: - eu-west-1c --- # IG master-2 apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: master-2 spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 autoscale: false iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 ## master set max = 1 min = 1 minSize: 1 maxSize: 1 machineType: c5a.large ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: master-2 project: master ## Labels for AWS cloudLabels: environment: Dev role: Master subnets: - eu-west-1c --- # IG master-3 apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: master-3 spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 autoscale: false iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 ## master set max = 1 min = 1 minSize: 1 maxSize: 1 machineType: c5a.large ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: master-3 project: master ## Labels for AWS cloudLabels: environment: Dev role: Master subnets: - eu-west-1c --- # IG nodes apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: worker spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 minSize: 5 maxSize: 50 machineType: r5a.xlarge onDemandBase: 10 onDemandAboveBase: 0 ## Rolling upgrade rollingUpdate: drainAndTerminate: true maxSurge: 3 maxUnavailable: 2 ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: nodes app: nodes ### Label to exclude from load balancers node.kubernetes.io/exclude-from-external-load-balancers: \"true\" ## Labels for AWS cloudLabels: k8s.io/cluster-autoscaler/enabled: \"\" k8s.io/cluster-autoscaler/cluster.example: \"\" k8s.io/cluster-autoscaler/node-template/label: \"\" environment: Dev role: Node subnets: - eu-west-1c","title":"kOps"},{"location":"kubernetes/kops/#kops","text":"","title":"kOps"},{"location":"kubernetes/kops/#example-file","text":"# kOps Cluster definition apiVersion: kops.k8s.io/v1alpha2 kind: Cluster metadata: ## Cluster name name: cluster.example spec: api: loadBalancer: class: Network type: Public assets: containerProxy: registry.com:9090 authorization: rbac: {} channel: stable cloudProvider: aws ## Bucket name and state file configBase: s3://bucket-name/cluster.example dnsZone: zone.example etcdClusters: - name: main cpuRequest: 200m etcdMembers: - instanceGroup: master-1 name: etcd-1 - instanceGroup: master-2 name: etcd-2 - instanceGroup: master-3 name: etcd-3 memoryRequest: 100Mi - name: events cpuRequest: 100m etcdMembers: - instanceGroup: master-1 name: etcd-1 - instanceGroup: master-2 name: etcd-2 - instanceGroup: master-3 name: etcd-3 memoryRequest: 100Mi iam: legacy: false ## Kubelet config kubelet: ### Enable to use metrics-server anonymousAuth: false ### Allow serviceaccount tokens to communicate with kubelet authorizationMode: Webhook authenticationTokenWebhook: true ## VPC CIDR access to Kubernetes API Server kubernetesApiAccess: [] kubernetesVersion: 1.22.6 masterPublicName: api.cluster.example ## VPC CIDR networkCIDR: 10.3.0.0/16 ## VPC ID networkID: vpc-00000000000 networking: ## CNI calico: majorVersion: v3 ### maximum transmission unit mtu: 1500 ## Internal kubernetes CIDR nonMasqueradeCIDR: 110.64.0.0/10 sshAccess: null subnets: - cidr: 12.0.0.0/24 id: subnet-00000000000 name: utility-eu-west-1c type: Utility zone: eu-west-1c - cidr: 10.3.2.0/23 id: subnet-1111111111 name: eu-west-1c type: Private zone: eu-west-1c topology: dns: type: Private masters: private nodes: private ## Addons awsLoadBalancerController: enabled: false clusterAutoscaler: enabled: true awsUseStaticInstanceList: false balanceSimilarNodeGroups: false expander: random image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.22.3 maxNodeProvisionTime: 15m0s newPodScaleUpDelay: 0s scaleDownDelayAfterAdd: 10m0s scaleDownUtilizationThreshold: \"0.5\" skipNodesWithLocalStorage: true skipNodesWithSystemPods: true cloudConfig: awsEBSCSIDriver: enabled: false managed: false nodeProblemDetector: enabled: true memoryRequest: 32Mi cpuRequest: 10m --- # IG master-1 apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: master-1 spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 autoscale: false iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 ## master set max = 1 min = 1 minSize: 1 maxSize: 1 machineType: c5a.large ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: master-1 project: master ## Labels for AWS cloudLabels: environment: Dev role: Master subnets: - eu-west-1c --- # IG master-2 apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: master-2 spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 autoscale: false iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 ## master set max = 1 min = 1 minSize: 1 maxSize: 1 machineType: c5a.large ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: master-2 project: master ## Labels for AWS cloudLabels: environment: Dev role: Master subnets: - eu-west-1c --- # IG master-3 apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: master-3 spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 autoscale: false iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 ## master set max = 1 min = 1 minSize: 1 maxSize: 1 machineType: c5a.large ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: master-3 project: master ## Labels for AWS cloudLabels: environment: Dev role: Master subnets: - eu-west-1c --- # IG nodes apiVersion: kops.k8s.io/v1alpha2 kind: InstanceGroup metadata: labels: kops.k8s.io/cluster: cluster.example name: worker spec: additionalSecurityGroups: ## Manage by Terraform - sg-00000000000 iam: ## Manage by Terraform profile: arn:aws:iam::00000000000:instance-profile/MASTERS associatePublicIp: false rootVolumeSize: 30 rootVolumeType: gp3 ## AMI id for region image: ami-02b4e72b17337d6c1 minSize: 5 maxSize: 50 machineType: r5a.xlarge onDemandBase: 10 onDemandAboveBase: 0 ## Rolling upgrade rollingUpdate: drainAndTerminate: true maxSurge: 3 maxUnavailable: 2 ## Labels for Kubernetes nodeLabels: kops.k8s.io/instancegroup: nodes app: nodes ### Label to exclude from load balancers node.kubernetes.io/exclude-from-external-load-balancers: \"true\" ## Labels for AWS cloudLabels: k8s.io/cluster-autoscaler/enabled: \"\" k8s.io/cluster-autoscaler/cluster.example: \"\" k8s.io/cluster-autoscaler/node-template/label: \"\" environment: Dev role: Node subnets: - eu-west-1c","title":"Example file"},{"location":"kubernetes/helm/helm/","text":"Helm \u00b6 Helm helps you manage Kubernetes applications. A Kubernetes manifest describes the resources (e.g., Deployments, Services, Pods, etc.) you want to create, and how you want those resources to run inside a cluster. apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment namespace: my-namespace labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 Helm Charts \u00b6 Helm uses a packaging format called Charts. A Helm Chart is a collection of files that describe a set of Kubernetes resources. Directory hierarchy \u00b6 . \u2514\u2500\u2500 my-release \u251c\u2500\u2500 charts \u251c\u2500\u2500 Chart.yaml \u251c\u2500\u2500 templates \u2502 \u251c\u2500\u2500 deployment.yaml \u2502 \u251c\u2500\u2500 _helpers.tpl \u2502 \u251c\u2500\u2500 hpa.yaml \u2502 \u251c\u2500\u2500 ingress.yaml \u2502 \u251c\u2500\u2500 NOTES.txt \u2502 \u251c\u2500\u2500 serviceaccount.yaml \u2502 \u251c\u2500\u2500 service.yaml \u2502 \u2514\u2500\u2500 tests \u2502 \u2514\u2500\u2500 test-connection.yaml \u2514\u2500\u2500 values.yaml Helm can be supplemented with some features: * Helm-diff * Helm-git * Helm-secrets * SOPS * VALS * Helmfile","title":"Helm"},{"location":"kubernetes/helm/helm/#helm","text":"Helm helps you manage Kubernetes applications. A Kubernetes manifest describes the resources (e.g., Deployments, Services, Pods, etc.) you want to create, and how you want those resources to run inside a cluster. apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment namespace: my-namespace labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80","title":"Helm"},{"location":"kubernetes/helm/helm/#helm-charts","text":"Helm uses a packaging format called Charts. A Helm Chart is a collection of files that describe a set of Kubernetes resources.","title":"Helm Charts"},{"location":"kubernetes/helm/helm/#directory-hierarchy","text":". \u2514\u2500\u2500 my-release \u251c\u2500\u2500 charts \u251c\u2500\u2500 Chart.yaml \u251c\u2500\u2500 templates \u2502 \u251c\u2500\u2500 deployment.yaml \u2502 \u251c\u2500\u2500 _helpers.tpl \u2502 \u251c\u2500\u2500 hpa.yaml \u2502 \u251c\u2500\u2500 ingress.yaml \u2502 \u251c\u2500\u2500 NOTES.txt \u2502 \u251c\u2500\u2500 serviceaccount.yaml \u2502 \u251c\u2500\u2500 service.yaml \u2502 \u2514\u2500\u2500 tests \u2502 \u2514\u2500\u2500 test-connection.yaml \u2514\u2500\u2500 values.yaml Helm can be supplemented with some features: * Helm-diff * Helm-git * Helm-secrets * SOPS * VALS * Helmfile","title":"Directory hierarchy"},{"location":"kubernetes/helm/helmfile/","text":"Helmfile \u00b6 Helmfile is a Helm wrapper that allows to manage multiple Helm Charts in a simpler way. Requirements \u00b6 Helmfile Helm Helm-diff Helm-secrets SOPS By default export HELM_SECRETS_BACKEND=sops . VALS export HELM_SECRETS_BACKEND=vals . Hierarchy \u00b6 . \u251c\u2500\u2500 bases \u2502 \u251c\u2500\u2500 environments.yaml ------------------------------------------> (Environments are defined. And versions are declared for the official Helm Charts) \u2502 \u2514\u2500\u2500 helmDefaults.yaml ------------------------------------------> (Default values of the Helm deployment. For example: wait or timeout) \u251c\u2500\u2500 helmfile.yaml --------------------------------------------------> (Main helmfile.yaml file) \u251c\u2500\u2500 releases -------------------------------------------------------> (Directory to locate all releases) \u2502 \u2514\u2500\u2500 my-release \u2502 \u251c\u2500\u2500 defaults.yaml ------------------------------------------> (Set default values for the release) \u2502 \u251c\u2500\u2500 envs ---------------------------------------------------> (Environment directory) \u2502 \u2502 \u251c\u2500\u2500 dev \u2502 \u2502 \u2502 \u251c\u2500\u2500 aws-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from AWS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Azure) \u2502 \u2502 \u2502 \u251c\u2500\u2500 gcp-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from GCP) \u2502 \u2502 \u2502 \u251c\u2500\u2500 hc-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Hashicorp Vault) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-local-secret-values.yaml --------------------> (Optional. File with values encrypted locally with SOPS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 .sops.yaml -> ../../../../templates/.sops.yaml -> (Symbolic link to .sops.yaml file) \u2502 \u2502 \u2502 \u251c\u2500\u2500 values.yaml.gotmpl -----------------------------> (Environment value using gotmpl) \u2502 \u2502 \u2502 \u2514\u2500\u2500 values.yaml ------------------------------------> (environment value file) \u2502 \u2502 \u251c\u2500\u2500 pre \u2502 \u2502 \u2502 \u251c\u2500\u2500 aws-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from AWS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Azure) \u2502 \u2502 \u2502 \u251c\u2500\u2500 gcp-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from GCP) \u2502 \u2502 \u2502 \u251c\u2500\u2500 hc-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Hashicorp Vault) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-local-secret-values.yaml --------------------> (Optional. File with values encrypted locally with SOPS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 .sops.yaml -> ../../../../templates/.sops.yaml -> (Symbolic link to .sops.yaml file) \u2502 \u2502 \u2502 \u251c\u2500\u2500 values.yaml.gotmpl -----------------------------> (Environment value using gotmpl) \u2502 \u2502 \u2502 \u2514\u2500\u2500 values.yaml ------------------------------------> (environment value file) \u2502 \u2502 \u2514\u2500\u2500 pro \u2502 \u2502 \u251c\u2500\u2500 aws-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from AWS) \u2502 \u2502 \u251c\u2500\u2500 az-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Azure) \u2502 \u2502 \u251c\u2500\u2500 gcp-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from GCP) \u2502 \u2502 \u251c\u2500\u2500 hc-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Hashicorp Vault) \u2502 \u2502 \u251c\u2500\u2500 az-local-secret-values.yaml --------------------> (Optional. File with values encrypted locally with SOPS) \u2502 \u2502 \u251c\u2500\u2500 .sops.yaml -> ../../../../templates/.sops.yaml -> (Symbolic link to .sops.yaml file) \u2502 \u2502 \u251c\u2500\u2500 values.yaml.gotmpl -----------------------------> (Environment value using gotmpl) \u2502 \u2502 \u2514\u2500\u2500 values.yaml ------------------------------------> (Environment value file) \u2502 \u2514\u2500\u2500 helmfile.yaml ------------------------------------------> (Helmfile.yaml release file) \u2514\u2500\u2500 templates ------------------------------------------------------> (Template directory) \u251c\u2500\u2500 default_values.yaml ----------------------------------------> (File with declared YAML Anchors that allow parameterizing the access to the value files) \u2514\u2500\u2500 .sops.yaml -------------------------------------------------> (File with SOPS encryption rules) Example files \u00b6 bases/environments.yaml \u00b6 --- templates: default_releases: &default_releases values: - metrics-server: 3.8.2 - reloader: 0.0.118 environments: dev: values: <<: *default_releases pre: values: <<: *default_releases pro: values: <<: *default_releases bases/helmDefaults.yaml \u00b6 --- # If set to \"Error\", return an error when a subhelmfile points to a # non-existent path. The default behavior is to print a warning and continue. missingFileHandler: Error # these labels will be applied to all releases in a Helmfile. Useful in templating if you have a helmfile per environment or customer and don't want to copy the same label to each release commonLabels: provisioning: helmfile # Default values to set for args along with dedicated keys that can be set by contributors, cli args take precedence over these. # In other words, unset values results in no flags passed to helm. # See the helm usage (helm SUBCOMMAND -h) for more info on default values when those flags aren't provided. helmDefaults: # wait for k8s resources via --wait. (default false) wait: false # if set and --wait enabled, will wait until all Jobs have been completed before marking the release as successful. It will wait for as long as --timeout (default false, Implemented in Helm3.5) waitForJobs: false # time in seconds to wait for any individual Kubernetes operation (like Jobs for hooks, and waits on pod/pvc/svc/deployment readiness) (default 300) timeout: 600 # verify the chart before upgrading (only works with packaged charts not directories) (default false) verify: false # forces resource update through delete/recreate if needed (default false) force: false ## enable TLS for request to Tiller (default false) #tls: true ## path to TLS CA certificate file (default \"$HELM_HOME/ca.pem\") #tlsCACert: \"path/to/ca.pem\" ## path to TLS certificate file (default \"$HELM_HOME/cert.pem\") #tlsCert: \"path/to/cert.pem\" ## path to TLS key file (default \"$HELM_HOME/key.pem\") #tlsKey: \"path/to/key.pem\" # limit the maximum number of revisions saved per release. Use 0 for no limit. (default 10) historyMax: 10 # when using helm 3.2+, automatically create release namespaces if they do not exist (default true) createNamespace: true # if used with charts museum allows to pull unstable charts for deployment, for example: if 1.2.3 and 1.2.4-dev versions exist and set to true, 1.2.4-dev will be pulled (default false) devel: false # When set to `true`, skips running `helm dep up` and `helm dep build` on this release's chart. # Useful when the chart is broken, like seen in https://github.com/roboll/helmfile/issues/1547 #skipDeps: false templates/.sops.yaml \u00b6 creation_rules: # PGP - path_regex: pgp-local.*.yaml$ pgp: B911C4BA2C10BF8BA1D9D005A680D32C9AE9B9CB # HC Vault - path_regex: hc-local-.*.yaml$ vault_path: \"sops/\" vault_kv_mount_name: \"secret/\" vault_kv_version: 2 # GCP KMS - path_regex: gcp-local-.*.yaml$ gcp_kms: projects/mygcproject/locations/global/keyRings/mykeyring/cryptoKeys/thekey # AWS KMS - path_regex: aws-local-.*.yaml$ kms: 'arn:aws:kms:us-west-2:0000000000000:key/fe86dd69-4132-404c-ab86-4269956b4500' # AZ Key Vault - path_regex: az-local-.*.yaml$ azure_keyvault: https://test.vault.azure.net/keys/sops/7b7c6b92999b42e79d744a0d4dc23e4adf templates/default_values.yaml \u00b6 --- templates: # Labels any_enc_labels: &any_enc_labels labels: enc: any sops_enc_labels: &sops_enc_labels labels: enc: sops vals_enc_labels: &vals_enc_labels labels: enc: vals # Values files default_values: &default_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml gotmpl_values: &gotmpl_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml.gotmpl remote_values: &remote_values values: - defaults.yaml - git::https://user:{{ env \"CI_JOB_TOKEN\" }}@git.company.com/demo/helmfiles/{{ .Environment.Name }}/values.yaml?ref=master - http://$HOSTNAME/artifactory/example-repo-local/test.tgz@values.yaml # Secrets on values files ## Local `SOPS` pgp_local_secret_values: &pgp_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/pgp-local-secret-values.yaml hc_local_secret_values: &hc_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/hc-local-secret-values.yaml gcp_local_secret_values: &gcp_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/gcp-local-secret-values.yaml aws_local_secret_values: &aws_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/aws-local-secret-values.yaml az_local_secret_values: &az_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/az-local-secret-values.yaml ## Remote `VALS` hc_remote_secret_values: &hc_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/hc-remote-secret-values.yaml gcp_remote_secret_values: &gcp_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/gcp-remote-secret-values.yaml aws_remote_secret_values: &aws_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/aws-remote-secret-values.yaml az_remote_secret_values: &az_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/az-remote-secret-values.yaml helmfile.yaml \u00b6 --- bases: - \"bases/helmDefaults.yaml\" - \"bases/environments.yaml\" repositories: - name: metrics-server url: https://kubernetes-sigs.github.io/metrics-server/ - name: reloader url: https://stakater.github.io/stakater-charts helmfiles: - \"releases/*/helmfile.yaml\" releases/metrics-server/helmfile.yaml \u00b6 ---- bases: - \"../../bases/helmDefaults.yaml\" - \"../../bases/environments.yaml\" --- {{ readFile \"../../templates/default_values.yaml\" }} releases: # https://github.com/helm/charts/blob/master/stable/metrics-server/values.yaml - name: metrics-server chart: metrics-server/metrics-server namespace: metrics-server version: {{ index (.Values | get \"metrics-server\" \"3.7.0\") }} <<: *any_enc_labels # You can use: any_enc_labels, sops_enc_labels or vals_enc_labels <<: *gotmpl_values # Depending on the type of values you need, # you can use the anchors declared in the defaults_values.yaml file. # Example: default_values, remote_values, gcp_remote_secret_values, gcp_local_secret_values ... releases/metrics-server/defaults.yaml \u00b6 # Custom values for metrics-server. # This is a YAML-formatted file. # Declare variables to be passed into your templates. --- args: # enable this if you have self-signed certificates, see: https://github.com/kubernetes-incubator/metrics-server - --kubelet-insecure-tls releases/metrics-server/envs/dev/values.yaml \u00b6 # Custom values to dev environment. # This is a YAML-formatted file. # Declare variables to be passed into your templates. --- podLabels: env: \"\" releases/metrics-server/envs/dev/values.yaml.gtmpl \u00b6 {{ readFile \"values.yaml\" | fromYaml | setValueAtPath \"podLabels.env\" .Environment.Name | toYaml }} Hemfile Commands \u00b6 Rendering dev environment \u00b6 $ helmfile template --environment dev Rendering dev environment for metrics-server \u00b6 $ helmfile template --environment dev --selector name=metrics-server Diff. Shows differences between the code and the cluster \u00b6 $ helmfile diff --environment dev --selector name=metrics-server Linters \u00b6 $ helmfile lint --environment dev Sync (Install) metrics-server release \u00b6 $ helmfile sync --environment dev --selector name=metrics-server Delete metrics-server release \u00b6 $ helmfile destroy --environment dev --selector name=metrics-server","title":"Helmfile"},{"location":"kubernetes/helm/helmfile/#helmfile","text":"Helmfile is a Helm wrapper that allows to manage multiple Helm Charts in a simpler way.","title":"Helmfile"},{"location":"kubernetes/helm/helmfile/#requirements","text":"Helmfile Helm Helm-diff Helm-secrets SOPS By default export HELM_SECRETS_BACKEND=sops . VALS export HELM_SECRETS_BACKEND=vals .","title":"Requirements"},{"location":"kubernetes/helm/helmfile/#hierarchy","text":". \u251c\u2500\u2500 bases \u2502 \u251c\u2500\u2500 environments.yaml ------------------------------------------> (Environments are defined. And versions are declared for the official Helm Charts) \u2502 \u2514\u2500\u2500 helmDefaults.yaml ------------------------------------------> (Default values of the Helm deployment. For example: wait or timeout) \u251c\u2500\u2500 helmfile.yaml --------------------------------------------------> (Main helmfile.yaml file) \u251c\u2500\u2500 releases -------------------------------------------------------> (Directory to locate all releases) \u2502 \u2514\u2500\u2500 my-release \u2502 \u251c\u2500\u2500 defaults.yaml ------------------------------------------> (Set default values for the release) \u2502 \u251c\u2500\u2500 envs ---------------------------------------------------> (Environment directory) \u2502 \u2502 \u251c\u2500\u2500 dev \u2502 \u2502 \u2502 \u251c\u2500\u2500 aws-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from AWS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Azure) \u2502 \u2502 \u2502 \u251c\u2500\u2500 gcp-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from GCP) \u2502 \u2502 \u2502 \u251c\u2500\u2500 hc-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Hashicorp Vault) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-local-secret-values.yaml --------------------> (Optional. File with values encrypted locally with SOPS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 .sops.yaml -> ../../../../templates/.sops.yaml -> (Symbolic link to .sops.yaml file) \u2502 \u2502 \u2502 \u251c\u2500\u2500 values.yaml.gotmpl -----------------------------> (Environment value using gotmpl) \u2502 \u2502 \u2502 \u2514\u2500\u2500 values.yaml ------------------------------------> (environment value file) \u2502 \u2502 \u251c\u2500\u2500 pre \u2502 \u2502 \u2502 \u251c\u2500\u2500 aws-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from AWS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Azure) \u2502 \u2502 \u2502 \u251c\u2500\u2500 gcp-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from GCP) \u2502 \u2502 \u2502 \u251c\u2500\u2500 hc-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Hashicorp Vault) \u2502 \u2502 \u2502 \u251c\u2500\u2500 az-local-secret-values.yaml --------------------> (Optional. File with values encrypted locally with SOPS) \u2502 \u2502 \u2502 \u251c\u2500\u2500 .sops.yaml -> ../../../../templates/.sops.yaml -> (Symbolic link to .sops.yaml file) \u2502 \u2502 \u2502 \u251c\u2500\u2500 values.yaml.gotmpl -----------------------------> (Environment value using gotmpl) \u2502 \u2502 \u2502 \u2514\u2500\u2500 values.yaml ------------------------------------> (environment value file) \u2502 \u2502 \u2514\u2500\u2500 pro \u2502 \u2502 \u251c\u2500\u2500 aws-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from AWS) \u2502 \u2502 \u251c\u2500\u2500 az-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Azure) \u2502 \u2502 \u251c\u2500\u2500 gcp-remote-secret-values.yaml ------------------> (Optional. File with reference to remote encrypted values from GCP) \u2502 \u2502 \u251c\u2500\u2500 hc-remote-secret-values.yaml -------------------> (Optional. File with reference to remote encrypted values from Hashicorp Vault) \u2502 \u2502 \u251c\u2500\u2500 az-local-secret-values.yaml --------------------> (Optional. File with values encrypted locally with SOPS) \u2502 \u2502 \u251c\u2500\u2500 .sops.yaml -> ../../../../templates/.sops.yaml -> (Symbolic link to .sops.yaml file) \u2502 \u2502 \u251c\u2500\u2500 values.yaml.gotmpl -----------------------------> (Environment value using gotmpl) \u2502 \u2502 \u2514\u2500\u2500 values.yaml ------------------------------------> (Environment value file) \u2502 \u2514\u2500\u2500 helmfile.yaml ------------------------------------------> (Helmfile.yaml release file) \u2514\u2500\u2500 templates ------------------------------------------------------> (Template directory) \u251c\u2500\u2500 default_values.yaml ----------------------------------------> (File with declared YAML Anchors that allow parameterizing the access to the value files) \u2514\u2500\u2500 .sops.yaml -------------------------------------------------> (File with SOPS encryption rules)","title":"Hierarchy"},{"location":"kubernetes/helm/helmfile/#example-files","text":"","title":"Example files"},{"location":"kubernetes/helm/helmfile/#basesenvironmentsyaml","text":"--- templates: default_releases: &default_releases values: - metrics-server: 3.8.2 - reloader: 0.0.118 environments: dev: values: <<: *default_releases pre: values: <<: *default_releases pro: values: <<: *default_releases","title":"bases/environments.yaml"},{"location":"kubernetes/helm/helmfile/#baseshelmdefaultsyaml","text":"--- # If set to \"Error\", return an error when a subhelmfile points to a # non-existent path. The default behavior is to print a warning and continue. missingFileHandler: Error # these labels will be applied to all releases in a Helmfile. Useful in templating if you have a helmfile per environment or customer and don't want to copy the same label to each release commonLabels: provisioning: helmfile # Default values to set for args along with dedicated keys that can be set by contributors, cli args take precedence over these. # In other words, unset values results in no flags passed to helm. # See the helm usage (helm SUBCOMMAND -h) for more info on default values when those flags aren't provided. helmDefaults: # wait for k8s resources via --wait. (default false) wait: false # if set and --wait enabled, will wait until all Jobs have been completed before marking the release as successful. It will wait for as long as --timeout (default false, Implemented in Helm3.5) waitForJobs: false # time in seconds to wait for any individual Kubernetes operation (like Jobs for hooks, and waits on pod/pvc/svc/deployment readiness) (default 300) timeout: 600 # verify the chart before upgrading (only works with packaged charts not directories) (default false) verify: false # forces resource update through delete/recreate if needed (default false) force: false ## enable TLS for request to Tiller (default false) #tls: true ## path to TLS CA certificate file (default \"$HELM_HOME/ca.pem\") #tlsCACert: \"path/to/ca.pem\" ## path to TLS certificate file (default \"$HELM_HOME/cert.pem\") #tlsCert: \"path/to/cert.pem\" ## path to TLS key file (default \"$HELM_HOME/key.pem\") #tlsKey: \"path/to/key.pem\" # limit the maximum number of revisions saved per release. Use 0 for no limit. (default 10) historyMax: 10 # when using helm 3.2+, automatically create release namespaces if they do not exist (default true) createNamespace: true # if used with charts museum allows to pull unstable charts for deployment, for example: if 1.2.3 and 1.2.4-dev versions exist and set to true, 1.2.4-dev will be pulled (default false) devel: false # When set to `true`, skips running `helm dep up` and `helm dep build` on this release's chart. # Useful when the chart is broken, like seen in https://github.com/roboll/helmfile/issues/1547 #skipDeps: false","title":"bases/helmDefaults.yaml"},{"location":"kubernetes/helm/helmfile/#templatessopsyaml","text":"creation_rules: # PGP - path_regex: pgp-local.*.yaml$ pgp: B911C4BA2C10BF8BA1D9D005A680D32C9AE9B9CB # HC Vault - path_regex: hc-local-.*.yaml$ vault_path: \"sops/\" vault_kv_mount_name: \"secret/\" vault_kv_version: 2 # GCP KMS - path_regex: gcp-local-.*.yaml$ gcp_kms: projects/mygcproject/locations/global/keyRings/mykeyring/cryptoKeys/thekey # AWS KMS - path_regex: aws-local-.*.yaml$ kms: 'arn:aws:kms:us-west-2:0000000000000:key/fe86dd69-4132-404c-ab86-4269956b4500' # AZ Key Vault - path_regex: az-local-.*.yaml$ azure_keyvault: https://test.vault.azure.net/keys/sops/7b7c6b92999b42e79d744a0d4dc23e4adf","title":"templates/.sops.yaml"},{"location":"kubernetes/helm/helmfile/#templatesdefault_valuesyaml","text":"--- templates: # Labels any_enc_labels: &any_enc_labels labels: enc: any sops_enc_labels: &sops_enc_labels labels: enc: sops vals_enc_labels: &vals_enc_labels labels: enc: vals # Values files default_values: &default_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml gotmpl_values: &gotmpl_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml.gotmpl remote_values: &remote_values values: - defaults.yaml - git::https://user:{{ env \"CI_JOB_TOKEN\" }}@git.company.com/demo/helmfiles/{{ .Environment.Name }}/values.yaml?ref=master - http://$HOSTNAME/artifactory/example-repo-local/test.tgz@values.yaml # Secrets on values files ## Local `SOPS` pgp_local_secret_values: &pgp_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/pgp-local-secret-values.yaml hc_local_secret_values: &hc_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/hc-local-secret-values.yaml gcp_local_secret_values: &gcp_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/gcp-local-secret-values.yaml aws_local_secret_values: &aws_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/aws-local-secret-values.yaml az_local_secret_values: &az_local_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/az-local-secret-values.yaml ## Remote `VALS` hc_remote_secret_values: &hc_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/hc-remote-secret-values.yaml gcp_remote_secret_values: &gcp_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/gcp-remote-secret-values.yaml aws_remote_secret_values: &aws_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/aws-remote-secret-values.yaml az_remote_secret_values: &az_remote_secret_values values: - defaults.yaml - envs/{{ .Environment.Name }}/values.yaml secrets: - envs/{{ .Environment.Name }}/az-remote-secret-values.yaml","title":"templates/default_values.yaml"},{"location":"kubernetes/helm/helmfile/#helmfileyaml","text":"--- bases: - \"bases/helmDefaults.yaml\" - \"bases/environments.yaml\" repositories: - name: metrics-server url: https://kubernetes-sigs.github.io/metrics-server/ - name: reloader url: https://stakater.github.io/stakater-charts helmfiles: - \"releases/*/helmfile.yaml\"","title":"helmfile.yaml"},{"location":"kubernetes/helm/helmfile/#releasesmetrics-serverhelmfileyaml","text":"---- bases: - \"../../bases/helmDefaults.yaml\" - \"../../bases/environments.yaml\" --- {{ readFile \"../../templates/default_values.yaml\" }} releases: # https://github.com/helm/charts/blob/master/stable/metrics-server/values.yaml - name: metrics-server chart: metrics-server/metrics-server namespace: metrics-server version: {{ index (.Values | get \"metrics-server\" \"3.7.0\") }} <<: *any_enc_labels # You can use: any_enc_labels, sops_enc_labels or vals_enc_labels <<: *gotmpl_values # Depending on the type of values you need, # you can use the anchors declared in the defaults_values.yaml file. # Example: default_values, remote_values, gcp_remote_secret_values, gcp_local_secret_values ...","title":"releases/metrics-server/helmfile.yaml"},{"location":"kubernetes/helm/helmfile/#releasesmetrics-serverdefaultsyaml","text":"# Custom values for metrics-server. # This is a YAML-formatted file. # Declare variables to be passed into your templates. --- args: # enable this if you have self-signed certificates, see: https://github.com/kubernetes-incubator/metrics-server - --kubelet-insecure-tls","title":"releases/metrics-server/defaults.yaml"},{"location":"kubernetes/helm/helmfile/#releasesmetrics-serverenvsdevvaluesyaml","text":"# Custom values to dev environment. # This is a YAML-formatted file. # Declare variables to be passed into your templates. --- podLabels: env: \"\"","title":"releases/metrics-server/envs/dev/values.yaml"},{"location":"kubernetes/helm/helmfile/#releasesmetrics-serverenvsdevvaluesyamlgtmpl","text":"{{ readFile \"values.yaml\" | fromYaml | setValueAtPath \"podLabels.env\" .Environment.Name | toYaml }}","title":"releases/metrics-server/envs/dev/values.yaml.gtmpl"},{"location":"kubernetes/helm/helmfile/#hemfile-commands","text":"","title":"Hemfile Commands"},{"location":"kubernetes/helm/helmfile/#rendering-dev-environment","text":"$ helmfile template --environment dev","title":"Rendering dev environment"},{"location":"kubernetes/helm/helmfile/#rendering-dev-environment-for-metrics-server","text":"$ helmfile template --environment dev --selector name=metrics-server","title":"Rendering dev environment for metrics-server"},{"location":"kubernetes/helm/helmfile/#diff-shows-differences-between-the-code-and-the-cluster","text":"$ helmfile diff --environment dev --selector name=metrics-server","title":"Diff. Shows differences between the code and the cluster"},{"location":"kubernetes/helm/helmfile/#linters","text":"$ helmfile lint --environment dev","title":"Linters"},{"location":"kubernetes/helm/helmfile/#sync-install-metrics-server-release","text":"$ helmfile sync --environment dev --selector name=metrics-server","title":"Sync (Install) metrics-server release"},{"location":"kubernetes/helm/helmfile/#delete-metrics-server-release","text":"$ helmfile destroy --environment dev --selector name=metrics-server","title":"Delete metrics-server release"},{"location":"kubernetes/helm/sops/","text":"SOPS \u00b6 SOPS is a tool that allows the encryption of local files. For our use case we use a Key from Key Vault declared in the .sops.yaml file for file encryption. SOPS Commands \u00b6 Show file \u00b6 $ cat file.yaml --- secrets: admin-creds: stringData: user: user-fake password: password-fake Encrypt file \u00b6 $ sops -e -i file.yaml $ cat file.yaml secrets: admin-creds: stringData: user: ENC[AES256_GCM,data:qiZNFqw=,iv:n/rXJHTD8D8DD4iI3zF5JpjDeZKp+SPItQSq0ue5VXc=,tag:DeD5PA4OwbsmoSNzzdQtSg==,type:str] password: ENC[AES256_GCM,data:7uDh0tJ0c/0VOw==,iv:ft33mHwy4zpmTvvq1mHOasy5/6rQR70Gv189IImeRoQ=,tag:9yP4pM8Y8oSwYCcuPso0jQ==,type:str] sops: kms: [] gcp_kms: [] azure_kv: - vault_url: <vault-url> name: <key-name> version: <version-name> created_at: \"2022-10-20T09:33:41Z\" enc: Z130UV0JoF4XLZHnJ-Y0hIHVfSLVqAGEr3niWMosL0vRF00TaoreX2bm_JLy8LvvxNKgS3jZXKW5RGujq4bA2_scKrAarkAvOhdg2N4CgykO1Yq4_9KP0ZbmD_FE0nzj3VN8fQsin5kOYrOPjVl5u1x8YLpsFQekt6E_Jj8TEcPaJPmj32sfdxvSWdASYxuJandU5o2aDeuZ_dkX6H9MaNdD68SJCNJQaSMm0IaWENVsyE24KaPKgkkqkXW8Pv92BtKw-Xgg6O2jYb4trokobkraE-Siaq0EwGbGPCi7zVlNH6ImPLG5vHTCLa9HEiG5Nd88A5OOA1yJ45f5NMpFug hc_vault: [] age: [] lastmodified: \"2022-10-20T09:33:42Z\" mac: ENC[AES256_GCM,data:cq4UrhEJq0x+66pZ7/Ga3DLeMohXnLiCiFOorF+cZYBJXviIj2Ncaw/jYTiEF3D5i8OBoZCz2O9pxSOpHHvrdiETvNfj/0/pGmPWmuflsPJ6Ehen8pKOdh91tJ0K2cBUWzym5X21SxcTjhjg1h8pIsK32e5mgWDu6Oai/G6gnjs=,iv:v6Ds1O2w8T5OE8X9wh8Q9Fez/Blwdxd87Wy7hSnoozM=,tag:a66zoL/C1U97tOE1/jI4cQ==,type:str] pgp: [] unencrypted_suffix: _unencrypted version: 3.7.3 Decrypt file \u00b6 $ sops -d -i file.yaml","title":"SOPS"},{"location":"kubernetes/helm/sops/#sops","text":"SOPS is a tool that allows the encryption of local files. For our use case we use a Key from Key Vault declared in the .sops.yaml file for file encryption.","title":"SOPS"},{"location":"kubernetes/helm/sops/#sops-commands","text":"","title":"SOPS Commands"},{"location":"kubernetes/helm/sops/#show-file","text":"$ cat file.yaml --- secrets: admin-creds: stringData: user: user-fake password: password-fake","title":"Show file"},{"location":"kubernetes/helm/sops/#encrypt-file","text":"$ sops -e -i file.yaml $ cat file.yaml secrets: admin-creds: stringData: user: ENC[AES256_GCM,data:qiZNFqw=,iv:n/rXJHTD8D8DD4iI3zF5JpjDeZKp+SPItQSq0ue5VXc=,tag:DeD5PA4OwbsmoSNzzdQtSg==,type:str] password: ENC[AES256_GCM,data:7uDh0tJ0c/0VOw==,iv:ft33mHwy4zpmTvvq1mHOasy5/6rQR70Gv189IImeRoQ=,tag:9yP4pM8Y8oSwYCcuPso0jQ==,type:str] sops: kms: [] gcp_kms: [] azure_kv: - vault_url: <vault-url> name: <key-name> version: <version-name> created_at: \"2022-10-20T09:33:41Z\" enc: Z130UV0JoF4XLZHnJ-Y0hIHVfSLVqAGEr3niWMosL0vRF00TaoreX2bm_JLy8LvvxNKgS3jZXKW5RGujq4bA2_scKrAarkAvOhdg2N4CgykO1Yq4_9KP0ZbmD_FE0nzj3VN8fQsin5kOYrOPjVl5u1x8YLpsFQekt6E_Jj8TEcPaJPmj32sfdxvSWdASYxuJandU5o2aDeuZ_dkX6H9MaNdD68SJCNJQaSMm0IaWENVsyE24KaPKgkkqkXW8Pv92BtKw-Xgg6O2jYb4trokobkraE-Siaq0EwGbGPCi7zVlNH6ImPLG5vHTCLa9HEiG5Nd88A5OOA1yJ45f5NMpFug hc_vault: [] age: [] lastmodified: \"2022-10-20T09:33:42Z\" mac: ENC[AES256_GCM,data:cq4UrhEJq0x+66pZ7/Ga3DLeMohXnLiCiFOorF+cZYBJXviIj2Ncaw/jYTiEF3D5i8OBoZCz2O9pxSOpHHvrdiETvNfj/0/pGmPWmuflsPJ6Ehen8pKOdh91tJ0K2cBUWzym5X21SxcTjhjg1h8pIsK32e5mgWDu6Oai/G6gnjs=,iv:v6Ds1O2w8T5OE8X9wh8Q9Fez/Blwdxd87Wy7hSnoozM=,tag:a66zoL/C1U97tOE1/jI4cQ==,type:str] pgp: [] unencrypted_suffix: _unencrypted version: 3.7.3","title":"Encrypt file"},{"location":"kubernetes/helm/sops/#decrypt-file","text":"$ sops -d -i file.yaml","title":"Decrypt file"},{"location":"qa/semantic_release/","text":"Semantic Release \u00b6 Semantic-release is an application created in nodejs, it allows to analyze the commits of a repository for the creation of tags. This allows greater control over the code displayed. How Semantic Selease works \u00b6 semantic-release uses the commit messages to determine the consumer impact of changes in the codebase. Following formalized conventions for commit messages, semantic-release automatically determines the next semantic version number, generates a changelog and publishes the release. By default, semantic-release uses Angular Commit Message Conventions . The commit message format can be changed with the preset or config options of the @semantic-release/commit-analyzer and @semantic-release/release-notes-generator plugins. Tools such as commitizen or commitlint can be used to help contributors and enforce valid commit messages. The table below shows which commit message gets you which release type when semantic-release runs (using the default configuration): Starting with v1.0.0: Commit message Release type Version fix(app): new fix Patch Release v1.0.1 feat(app): new feature MINOR Feature Release v1.1.0 perf(app): a change BREAKING CHANGE: change to major version Major Breaking Release v2.0.0 Starting from forecast-v1.2.5, we can add multiple types of commits but it will only count one: Commit message Version fix(app): new fix + fix(app): other fix v1.2.6 feat(app): new feature + feat(app): other feature v1.3.0","title":"Semantic Release"},{"location":"qa/semantic_release/#semantic-release","text":"Semantic-release is an application created in nodejs, it allows to analyze the commits of a repository for the creation of tags. This allows greater control over the code displayed.","title":"Semantic Release"},{"location":"qa/semantic_release/#how-semantic-selease-works","text":"semantic-release uses the commit messages to determine the consumer impact of changes in the codebase. Following formalized conventions for commit messages, semantic-release automatically determines the next semantic version number, generates a changelog and publishes the release. By default, semantic-release uses Angular Commit Message Conventions . The commit message format can be changed with the preset or config options of the @semantic-release/commit-analyzer and @semantic-release/release-notes-generator plugins. Tools such as commitizen or commitlint can be used to help contributors and enforce valid commit messages. The table below shows which commit message gets you which release type when semantic-release runs (using the default configuration): Starting with v1.0.0: Commit message Release type Version fix(app): new fix Patch Release v1.0.1 feat(app): new feature MINOR Feature Release v1.1.0 perf(app): a change BREAKING CHANGE: change to major version Major Breaking Release v2.0.0 Starting from forecast-v1.2.5, we can add multiple types of commits but it will only count one: Commit message Version fix(app): new fix + fix(app): other fix v1.2.6 feat(app): new feature + feat(app): other feature v1.3.0","title":"How Semantic Selease works"}]}